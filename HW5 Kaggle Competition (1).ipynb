{"cells":[{"metadata":{"_uuid":"a6717103051c3f8b781161d917a4fe7352be60e4"},"cell_type":"markdown","source":"Brandon Oâ€™Neill<br>\nCSPB 3202<br>\nAugust 3, 2020<br>\nHW5 Kaggle Competition<br>\n# Sources\nI used a variety of sources found throughout the competition as far as Kaggle implementation, loading the images and other aspects of the Keras training.\n\n# Introduction\nThis problem is basically an image classification problem where the decision will be whether or not the image shows signs of cancer. More specifically, we are predicting the probability of the center (32x32px) of the image contains at least one pixel of tumor tissue. The data itself has around 220,000 labeled pictures for training and 55,000 pictures for testing."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"from glob import glob \nimport numpy as np\nimport pandas as pd\nimport keras,cv2,os\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"077d54fd1297b6707ea5f202ec706085599225c6"},"cell_type":"markdown","source":"# Exploratory Data Analysis\nFirst I am going to load the data and take a sample of 1000 photos for exploratory testing."},{"metadata":{"_uuid":"d72f6d8131277d5a1452d92677bcaaae8117165b","trusted":true},"cell_type":"code","source":"\npath = \"../input/\"\ntrain = path + 'train/'\ntest = path + 'test/'\n\ndf = pd.DataFrame({'path': glob(os.path.join(train,'*.tif'))})\ndf['id'] = df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\nlabels = pd.read_csv(path+\"train_labels.csv\")\ndf = df.merge(labels, on = \"id\")\n\ndef ld(N,df):\n    X = np.zeros([N,96,96,3],dtype=np.uint8)\n    y = np.squeeze(df.as_matrix(columns=['label']))[0:N]\n    for i, row in df.iterrows()\n        if i == N:\n            break\n        X[i] = cv2.imread(row['path'])\n          \n    return X,y\nn = 1000\nX,y = ld(n, df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then I will check the distribution of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.bar([1,0], [(y==0).sum(), (y==1).sum()])\nplt.xticks([1,0],[\"No Cancer\",\"Cancer\"])\nplt.ylabel(\"# of images\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above histogram, we can see that there a nearly 60/40 split in terms of No Cancer/Cancer throughout the data. <br>\n\nNext I will print some images with the corresponding labels so we get an idea of what potential characteristics the model will be looking at. The 0 indicates no cancer while the 1 indicates cancer."},{"metadata":{"_uuid":"ffed68f7b732222097006f1047744950ad085ed8","scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfor pic,i in enumerate(np.random.randint(0,1000,4)):\n    a = fig.add_subplot(2, 4, pic+1, xticks=[], yticks=[])\n    plt.imshow(X[i])\n    a.set_title('Label: ' + str(y[i]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3671a84db204421a58fca08010e38a99490b1e27"},"cell_type":"markdown","source":"There are some noticeable differences in terms of color and brightness. The color of the non cancer cells tend to be brighter than the cancer cells."},{"metadata":{"_uuid":"c3bd89f6d9e00472c46b1c9c617e3d090c9fccce"},"cell_type":"markdown","source":"# The Model Architecture\nThe model I will be using is a neural network called Keras. From the documentation, this is a convolutional neural network that has three layers to it; the convolution, the batch normalization, and the pooling/dropout. A neural network like this would be beneficial for this problem because it can learn what cancer cells look like from the pixel level and then make a decision based on probability without much intervention. "},{"metadata":{"_uuid":"30e69a2a034e279da6eeb0fc09f1a58b58fc0401","trusted":true},"cell_type":"code","source":"\nN = df[\"path\"].size\nX,y = ld(N=N,df=df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60644d18d00811a12f6270ac42f8c745902018a8","trusted":true},"cell_type":"code","source":"training_portion = 0.8 # Specify training/validation ratio\nsplit_idx = int(np.round(training_portion * y.shape[0])) #Compute split idx\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9434b86b47f6132843b328d4fbf326aad01b24c0","trusted":true},"cell_type":"code","source":"# these model numbers and setup were sourced from https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-10min-0-925-lb \n\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\ndropout_conv = 0.3\ndropout_dense = 0.5\n\nmodel = Sequential()\n\n\nmodel.add(Conv2D(first_filters, kernel_size, input_shape = (96, 96, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(first_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(second_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(third_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Dense(256, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(dropout_dense))\n\nmodel.add(Dense(1, activation = \"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the model is formatted, I will run 3 epochs on the model. This is similar to what we learned in class."},{"metadata":{"_uuid":"594a0db99d65d223695d4dd8d9437d915363e055","trusted":true},"cell_type":"code","source":"batch_size = 50\n\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(0.001), \n              metrics=['accuracy'])\nepochs = 3\nfor epoch in range(epochs):\n    iterations = np.floor(split / batch).astype(int) \n    for i in t:\n        st = i * batch\n        xB = X[st:st+batch]\n        yB = y[st:st+batch] \n        metrics = model.train_on_batch(xB, yB)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is where the actual model will run against the test data and I will create a file for submission."},{"metadata":{"trusted":true,"_uuid":"6d5d71c896efb4018434d00d1aab03d3355cb367"},"cell_type":"code","source":"main = path + 'test/'\ntest = glob(os.path.join(main,'*.tif'))\nsub = pd.DataFrame()\nbt = 5000\nmaxIn = len(test)\nfor i in range(0, maxIn, bt):\n    df = pd.DataFrame({'path': test_files[i:i+bt]}) \n    df['id'] = df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) \n    df['image'] = df['path'].map(cv2.imread)\n    k = np.stack(test_df[\"image\"].values) \n    predictions = model.predict(k,verbose = 1)\n    test_df['label'] = predictions\n    sub = pd.concat([sub, test_df[[\"id\", \"label\"]]])\n    \nsub.to_csv(\"testResults.csv\", index = False, header = True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}